{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_pubmed = pd.read_csv('pubmed_part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "def get_biobert_embedding(text):\n",
    "    \"\"\"\n",
    "    Get BioBERT embedding for a text\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "    Returns:\n",
    "        numpy.ndarray: Embedding vector\n",
    "    \"\"\"\n",
    "    # Tokenize text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, \n",
    "                      truncation=True, padding=True)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use [CLS] token embedding or mean of all tokens\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Replace the Word2Vec functions\n",
    "def get_sentence_vector(sentence):\n",
    "    \"\"\"\n",
    "    Get embedding vector for a sentence using BioBERT\n",
    "    \"\"\"\n",
    "    return get_biobert_embedding(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Add tqdm to pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "def process_in_batches(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "        all_embeddings.extend(embeddings)\n",
    "    return all_embeddings\n",
    "\n",
    "def process_embeddings(df, batch_size=32):\n",
    "    \"\"\"\n",
    "    Process embeddings for abstract texts in dataframe using batches\n",
    "    \"\"\"\n",
    "    print(\"Generating embeddings...\")\n",
    "    \n",
    "    # Process abstract texts in batches\n",
    "    abstract_texts = df['abstract_text'].tolist()\n",
    "    abstract_embeddings = process_in_batches(abstract_texts, batch_size)\n",
    "    df['abstract_vector'] = abstract_embeddings\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sample of 10 rows from df_pubmed_1\n",
    "# df_pubmed_sample = df_pubmed.sample(n=10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>abstract_text</th>\n",
       "      <th>abstract_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9932</th>\n",
       "      <td>8825533</td>\n",
       "      <td>The effect of ranitidine on postoperative naus...</td>\n",
       "      <td>[0.06694699, -0.025046367, 0.029512007, 0.1212...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21459</th>\n",
       "      <td>10213349</td>\n",
       "      <td>Physical training improves exercise capacity i...</td>\n",
       "      <td>[0.0422495, 0.022081487, -0.019242544, 0.15092...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>8853730</td>\n",
       "      <td>To study the effect of HIV-1 resistance to lam...</td>\n",
       "      <td>[0.16013415, -0.019622369, 0.08715239, 0.13335...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16554</th>\n",
       "      <td>9572224</td>\n",
       "      <td>To test the null hypothesis of no association ...</td>\n",
       "      <td>[0.02369017, -0.08694814, 0.023889067, 0.07609...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3699</th>\n",
       "      <td>7802127</td>\n",
       "      <td>Three issues relevant to revising the DSM-III-...</td>\n",
       "      <td>[0.0974562, -0.009266093, 0.04439923, -0.01585...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19969</th>\n",
       "      <td>9892302</td>\n",
       "      <td>This study compared the effect of clozapine an...</td>\n",
       "      <td>[0.012985589, -0.03693167, 0.028529573, 0.0491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17948</th>\n",
       "      <td>9702441</td>\n",
       "      <td>To evaluate the efficacy of combining electrot...</td>\n",
       "      <td>[0.12210363, -0.15359151, 0.026292726, 0.22490...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17605</th>\n",
       "      <td>9673476</td>\n",
       "      <td>To compare the safety and efficacy of polyacry...</td>\n",
       "      <td>[0.12443222, -0.06251675, 0.012834996, 0.18939...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18166</th>\n",
       "      <td>9721763</td>\n",
       "      <td>To compare intraoperative and postoperative ou...</td>\n",
       "      <td>[0.09425821, -0.041623063, 0.047945935, 0.1804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>7659476</td>\n",
       "      <td>To compare the reactogenicity of a licensed co...</td>\n",
       "      <td>[0.15273434, -0.090804145, 0.14593138, 0.19430...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       abstract_id                                      abstract_text  \\\n",
       "9932       8825533  The effect of ranitidine on postoperative naus...   \n",
       "21459     10213349  Physical training improves exercise capacity i...   \n",
       "10146      8853730  To study the effect of HIV-1 resistance to lam...   \n",
       "16554      9572224  To test the null hypothesis of no association ...   \n",
       "3699       7802127  Three issues relevant to revising the DSM-III-...   \n",
       "19969      9892302  This study compared the effect of clozapine an...   \n",
       "17948      9702441  To evaluate the efficacy of combining electrot...   \n",
       "17605      9673476  To compare the safety and efficacy of polyacry...   \n",
       "18166      9721763  To compare intraoperative and postoperative ou...   \n",
       "2851       7659476  To compare the reactogenicity of a licensed co...   \n",
       "\n",
       "                                         abstract_vector  \n",
       "9932   [0.06694699, -0.025046367, 0.029512007, 0.1212...  \n",
       "21459  [0.0422495, 0.022081487, -0.019242544, 0.15092...  \n",
       "10146  [0.16013415, -0.019622369, 0.08715239, 0.13335...  \n",
       "16554  [0.02369017, -0.08694814, 0.023889067, 0.07609...  \n",
       "3699   [0.0974562, -0.009266093, 0.04439923, -0.01585...  \n",
       "19969  [0.012985589, -0.03693167, 0.028529573, 0.0491...  \n",
       "17948  [0.12210363, -0.15359151, 0.026292726, 0.22490...  \n",
       "17605  [0.12443222, -0.06251675, 0.012834996, 0.18939...  \n",
       "18166  [0.09425821, -0.041623063, 0.047945935, 0.1804...  \n",
       "2851   [0.15273434, -0.090804145, 0.14593138, 0.19430...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_embeddings(df_pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All vectors have same length: True\n",
      "Vector lengths: [768]\n",
      "First vector type: <class 'numpy.ndarray'>\n",
      "First vector shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "# Check length of abstract vectors\n",
    "def check_length(df):\n",
    "    vector_lengths = df['abstract_vector'].apply(len)\n",
    "    print(\"\\nAll vectors have same length:\", all(vector_lengths == vector_lengths.iloc[0]))\n",
    "    print(\"Vector lengths:\", vector_lengths.unique())\n",
    "\n",
    "def check_type(df):\n",
    "    print(\"First vector type:\", type(df['abstract_vector'].iloc[0]))\n",
    "    print(\"First vector shape:\", df['abstract_vector'].iloc[0].shape)\n",
    "\n",
    "check_length(df_pubmed)\n",
    "check_type(df_pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(df, num):\n",
    "    df_export = df.copy()\n",
    "    df_export['abstract_vector'] = df_export['abstract_vector'].apply(lambda x: ','.join(map(str, x)))\n",
    "    df_export.to_csv(f'processed_embeddings_{num}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings(df_pubmed, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings(df_pubmed, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings(df_pubmed, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings(df_pubmed, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings(df_pubmed, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings(df_pubmed, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings(df_pubmed, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings(df_pubmed, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
